#!/usr/bin/env python3
"""
Build script to combine multiple source files into a single distributable file.
Similar to how Black and Poetry handle their distribution.
"""

import ast
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple


def get_imports(content: str) -> Tuple[List[str], List[str]]:
    """Extract import statements and imported names from Python code.

    Returns:
        Tuple of (import statements, imported names)
    """
    tree = ast.parse(content)
    imports = []
    imported_names = []

    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for name in node.names:
                imports.append(f"import {name.name}")
                imported_names.append(name.asname or name.name)
        elif isinstance(node, ast.ImportFrom):
            names = [n.name for n in node.names]
            if node.module:
                imports.append(f"from {node.module} import {', '.join(names)}")
                imported_names.extend(names)

    return imports, imported_names


def get_source_files(src_dir: Path) -> List[Path]:
    """Get all Python source files in the project."""
    files = []
    # First check direct children of src_dir for test files
    for file in src_dir.glob("*.py"):
        if file.name != "__init__.py" and "build_single.py" not in str(file):
            files.append(file)

    # Then walk subdirectories for package files
    for root, _, filenames in os.walk(src_dir):
        root_path = Path(root)
        if root_path == src_dir:  # Skip direct children since we already got them
            continue
        for filename in filenames:
            if filename.endswith(".py"):
                path = root_path / filename
                # Skip __init__.py files and the build script itself
                if filename != "__init__.py" and "build_single.py" not in str(path):
                    files.append(path)
    return sorted(files)


def clean_content(content: str, pkg_name: str = "repomapper") -> str:
    """Clean up file content by removing imports and adjusting relative imports."""
    # Remove any existing imports
    tree = ast.parse(content)
    lines = content.split("\n")
    import_lines = set()

    for node in ast.walk(tree):
        if isinstance(node, (ast.Import, ast.ImportFrom)):
            start = node.lineno - 1
            end = node.end_lineno if hasattr(node, "end_lineno") else start + 1
            for i in range(start, end):
                import_lines.add(i)

    cleaned = [line for i, line in enumerate(lines) if i not in import_lines]

    while cleaned and not cleaned[0].strip():
        cleaned.pop(0)
    cleaned_content = "\n".join(cleaned)

    # Convert relative imports to absolute
    cleaned_content = re.sub(
        r"from \.([\w.]+) import", rf"from {pkg_name}.src.\1 import", cleaned_content
    )

    return cleaned_content


def combine_files(output_file: Path, pkg_name: str = "repomapper"):
    """Combine all source files into a single distributable file."""
    # Try relative to the output file for tests first
    src_dir = output_file.parent / pkg_name / "src"
    if not src_dir.exists():
        # Fall back to package install path
        src_dir = Path(__file__).parent.parent / "src" / pkg_name
        if not src_dir.exists():
            raise FileNotFoundError(
                f"Source directory not found at {src_dir} or relative to output"
            )

    files = get_source_files(src_dir)
    content_by_file: Dict[Path, str] = {}

    for file in files:
        with open(file) as f:
            content = f.read()
            content_by_file[file] = content

    combined_content = [
        "#!/usr/bin/env python3",
        '"""',
        "Single-file distribution of the code map generator.",
        "This file was automatically generated by build_single.py.",
        "Do not edit directly.",
        '"""',
        "",
        "import ast",
        "import argparse",
        "import json",
        "import os",
        "import re",
        "import subprocess",
        "import sys",
        "from abc import ABC, abstractmethod",
        "from collections import defaultdict",
        "from dataclasses import dataclass",
        "from enum import Enum",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Set, Tuple, TypedDict, NamedTuple",
        "",
        "from dataclasses import dataclass",
        "",
    ]

    # Sort files according to dependencies, then filename
    sorted_files = sorted(
        files,
        key=lambda f: (
            0
            if f.name == "types.py"
            else 1
            if f.name in {"symbols.py", "handlers/base.py"}
            else 2
            if f.name == "ignore.py"
            else 3
            if f.name == "core.py"
            else 4
            if "handlers" in str(f)
            else 5,
            f.name,
        ),
    )

    seen_content = set()

    for file in sorted_files:
        content = content_by_file[file]
        cleaned = clean_content(content, pkg_name)
        if cleaned.strip():
            if cleaned in seen_content:
                continue
            seen_content.add(cleaned)

            try:
                rel_path = file.relative_to(src_dir.parent)
            except ValueError:
                rel_path = file
            combined_content.extend(["", f"# --- From: {rel_path} ---", cleaned])

    if not any(
        'if __name__ == "__main__":' in content for content in content_by_file.values()
    ):
        combined_content.extend(["", 'if __name__ == "__main__":', "    main()"])

    output_file.write_text("\n".join(combined_content))
    output_file.chmod(output_file.stat().st_mode | 0o111)
    print(f"Created combined file: {output_file}")


def main():
    """Main entry point."""
    output = Path("repomapper")
    combine_files(output)


if __name__ == "__main__":
    main()
